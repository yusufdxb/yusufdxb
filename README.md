# Yusuf Guenena

Robotics & Embedded Systems Engineer  
Autonomous â€¢ Assistive â€¢ Medical Robotics  

M.S. Robotics Engineering (Intelligent Control) â€” Wayne State University

I build **end-to-end robotic systems** that tightly integrate perception, control, embedded electronics, and real hardware, with a focus on **safety-critical and assistive applications**.

---

## ğŸ”§ What I Build

I design and prototype **real-world robotic systems**, not simulations only. My work emphasizes:

- Perception, control, and humanâ€“robot interaction  
- ROS 2 (Humble / Jazzy) system integration  
- Embedded electronics & sensor fusion  
- Hardwareâ€“software co-design  

My interests center on **medical robotics, assistive autonomy, and intelligent systems**.

---

## ğŸš€ Flagship Projects

### ğŸ¦® GO2 Seeing-Eye Dog (Research Project)

Assistive robotics prototype using **ROS 2**, onboard perception, and multimodal humanâ€“robot interaction.  
Focused on real-world navigation and guidance for visually impaired users.
ROS 2â€“based autonomy, perception, and interaction framework for assistive navigation using Unitree GO2, targeting safe and intuitive mobility for visually impaired users.

This project constitutes a Masterâ€™s thesis centered on multimodal humanâ€“robot interaction and safety-critical perception for assistive robotics. The core research investigates audio-visual grounding for human intent inference, where a user issues a spoken command (e.g., â€œcome hereâ€), the robot performs audio perception and sound-source localization, orients toward the acoustic cue, executes vision-based human identification, confirms user intent, and subsequently performs human-aware, safety-constrained navigation toward the caller.

Primary research themes include:
- Audio perception and sound-source localization for user-driven interaction
- Audio-guided visual attention and human identification
- Multimodal intent grounding and interaction confidence modeling
- Safety-critical scene perception (stairs, curbs, doors, narrow passages, dynamic obstacles)
- Human-aware navigation and conservative assistive behaviors

**Status:** Active research and development (ROS 2 stack integration and experimental validation in progress).

[![GO2 Demo](https://i.ytimg.com/vi/EAaj1M6WRpo/hqdefault.jpg)](https://youtube.com/shorts/EAaj1M6WRpo)

---

### ğŸ¥ RADAR â€” Remote Autonomous Doctor Assistance Robot
ROS 2â€“based medical telepresence robot enabling real-time remote control, physiological monitoring, and clinician interaction through a custom Qt GUI. Autonomous lab deliveries using slam and april tags.

**Tech:** ROS 2, C++, Python, MAX30102, TurtleBot3, Qt6, SLAM
ğŸ‘‰ https://github.com/yusufdxb/RADAR-Telepresence-Robot

---

### â™»ï¸ EcoSort â€” Smart Waste Sorting Bin
Embedded mechatronic system for automated waste classification using multi-sensor fusion and mechanically actuated sorting.

**Tech:** Arduino, load cells, color & IR sensors, servos, CAD  
ğŸ‘‰ https://github.com/yusufdxb/EcoSort-bin

---


## ğŸ§  Technical Stack

- **Robotics:** ROS 2, Gazebo, RViz, tf2  
- **Languages:** C++, Python, MATLAB  
- **Embedded:** Arduino, Raspberry Pi, sensors & actuators  
- **Tools:** Linux, Git, Qt6, Fusion 360  

---

## ğŸ¯ Current Focus

- Assistive autonomy and navigation for legged robots (Unitree GO2)  
- Safety-critical perception (doors, stairs, obstacles)  
- Robust ROS 2 system design for real hardware  

---

## ğŸ“« Contact

- Email: yusuf.a.guenena@gmail.com  
- LinkedIn: https://www.linkedin.com/in/yusuf-guenena
